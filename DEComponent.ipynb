{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession ,  Row , SQLContext \n",
    "from pyspark.sql.functions import col,concat_ws, expr, explode, lit, when, from_json , StructType, StringType, to_json, udf, regexp_extract, count, sum, first, collect_list\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, IntegerType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkRuntimeError",
     "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPySparkRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# spark = SparkSession.builder\\\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#         .master(\"local[*]\") \\\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#         .appName('Data Engineer & Data Science Component')\\\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#         .config('spark.ui.port', '4041')\\\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#         .config(\"spark.executor.memory\", \"4g\") \\\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#         .getOrCreate()\u001b[39;00m\n\u001b[0;32m      8\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData Engineer & Data Science Component\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspark.ui.port\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m4040\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m---> 12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\examver\\Lib\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\examver\\Lib\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\examver\\Lib\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\examver\\Lib\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\examver\\Lib\\site-packages\\pyspark\\java_gateway.py:107\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[0;32m    108\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAVA_GATEWAY_EXITED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[0;32m    113\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
      "\u001b[1;31mPySparkRuntimeError\u001b[0m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder\\\n",
    "#         .master(\"local[*]\") \\\n",
    "#         .appName('Data Engineer & Data Science Component')\\\n",
    "#         .config('spark.ui.port', '4041')\\\n",
    "#         .config(\"spark.executor.memory\", \"4g\") \\\n",
    "#         .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\") \\\n",
    "        .appName('Data Engineer & Data Science Component')\\\n",
    "        .config('spark.ui.port', '4040')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch More article from Scopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your Scopus Search API endpoint\n",
    "search_base_url = \"https://api.elsevier.com/content/search/scopus\"\n",
    "abstract_doi_url = \"https://api.elsevier.com/content/abstract/doi/\"\n",
    "abstract_scopus_url = \"https://api.elsevier.com/content/abstract/scopus_id/\"\n",
    "abstract_eid_url = \"https://api.elsevier.com/content/abstract/eid/\"\n",
    "\n",
    "# Your API Key\n",
    "api_key = \"01d58db39c61dd0939ce840a1321fbc0\"\n",
    "\n",
    "# Query for searching articles\n",
    "search_query = \"TITLE-ABS-KEY(chulalongkorn) AND (PUBYEAR < 2018 OR PUBYEAR > 2023)\"\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    \"X-ELS-APIKey\": api_key,\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Parameters for Scopus search\n",
    "search_params = {\n",
    "    \"query\": search_query,\n",
    "    \"count\": 1,  # Fetch only 1 result per page\n",
    "}\n",
    "\n",
    "# Create the 'additional_file' folder if it doesn't exist\n",
    "output_folder = \"./Raw_data/Additional_Data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Maximum number of results to fetch\n",
    "max_results = 1000  # Adjust as needed\n",
    "total_results = 0\n",
    "travelled = 0\n",
    "\n",
    "# Fetch results one at a time\n",
    "while total_results < max_results:\n",
    "    search_params['start'] = travelled  # Increment by 1 for each article\n",
    "    \n",
    "    # Send the request for the current article\n",
    "    search_response = requests.get(search_base_url, headers=headers, params=search_params)\n",
    "    \n",
    "    if search_response.status_code == 200:\n",
    "        search_data = search_response.json()\n",
    "        entries = search_data.get(\"search-results\", {}).get(\"entry\", [])\n",
    "        \n",
    "        if not entries:\n",
    "            print(f\"No more articles found after {total_results} results.\")\n",
    "            break\n",
    "        \n",
    "        # Extract the DOI and fetch details for the article\n",
    "        result = entries[0]  # Since count=1, there is only one entry\n",
    "        doi = result.get(\"prism:doi\")\n",
    "        scopus_id = result.get(\"dc:identifier\")\n",
    "        eid = result.get(\"eid\")\n",
    "        \n",
    "        if doi:\n",
    "            # Retrieve metadata for the article\n",
    "            abstract_url = f\"{abstract_doi_url}{doi}\"\n",
    "            abstract_response = requests.get(abstract_url, headers=headers)\n",
    "            \n",
    "            if abstract_response.status_code == 200:\n",
    "                article_data = abstract_response.json()\n",
    "                \n",
    "                # Save the article's data as a separate JSON file\n",
    "                file_path = os.path.join(output_folder, f\"article_{travelled + 1}.json\")\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                    json.dump(article_data, json_file, ensure_ascii=False, indent=4)\n",
    "                    \n",
    "                total_results += 1\n",
    "            else:\n",
    "                print(f\"Failed to retrieve metadata for DOI {doi}: {abstract_response.status_code}\")\n",
    "                \n",
    "        elif scopus_id:\n",
    "            # Retrieve metadata for the article\n",
    "            abstract_url = f\"{abstract_scopus_url}{scopus_id}\"\n",
    "            abstract_response = requests.get(abstract_url, headers=headers)\n",
    "            \n",
    "            if abstract_response.status_code == 200:\n",
    "                article_data = abstract_response.json()\n",
    "                \n",
    "                # Save the article's data as a separate JSON file\n",
    "                file_path = os.path.join(output_folder, f\"article_{travelled + 1}.json\")\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                    json.dump(article_data, json_file, ensure_ascii=False, indent=4)\n",
    "                    \n",
    "                total_results += 1\n",
    "            else:\n",
    "                print(f\"Failed to retrieve metadata for Scopus ID {scopus_id}: {abstract_response.status_code}\")\n",
    "        elif eid:\n",
    "            # Retrieve metadata for the article\n",
    "            abstract_url = f\"{abstract_eid_url}{eid}\"\n",
    "            abstract_response = requests.get(abstract_url, headers=headers)\n",
    "            \n",
    "            if abstract_response.status_code == 200:\n",
    "                article_data = abstract_response.json()\n",
    "                \n",
    "                # Save the article's data as a separate JSON file\n",
    "                file_path = os.path.join(output_folder, f\"article_{travelled + 1}.json\")\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                    json.dump(article_data, json_file, ensure_ascii=False, indent=4)\n",
    "                    \n",
    "                total_results += 1\n",
    "            else:\n",
    "                print(f\"Failed to retrieve metadata for EID {eid}: {abstract_response.status_code}\")\n",
    "        else:\n",
    "            print(f\"No DOI found for article {travelled + 1}. Skipping.\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for article {travelled + 1}: {search_response.status_code}\")\n",
    "        break\n",
    "    travelled += 1\n",
    "\n",
    "print(f\"All data has been saved to the '{output_folder}' folder. Fetched a total of {total_results} articles.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./Raw_data\"  # Replace with your directory path\n",
    "base_dir = './test'\n",
    "\n",
    "df = spark.read.option(\"multiline\", True).option(\"recursiveFileLookup\", True).json(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted column selection\n",
    "base_data_selected_columns = [\n",
    "    #normal columns\n",
    "    col(\"abstracts-retrieval-response.language.@xml:lang\").alias(\"language\"), #\n",
    "    col(\"abstracts-retrieval-response.coredata.srctype\").alias(\"source_type\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:doi\").alias(\"prism:doi\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:coverDate\").alias(\"cover_date\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:aggregationType\").alias(\"aggregation_type\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.source-id\").alias(\"source_id\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.citedby-count\").alias(\"citedby_count\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:volume\").alias(\"volume\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.subtype\").alias(\"subtype\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:title\").alias(\"title\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:issueIdentifier\").alias(\"issue_identifier\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.subtypeDescription\").alias(\"subtype_description\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:publicationName\").alias(\"publication_name\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:startingPage\").alias(\"starting_page\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:endingPage\").alias(\"ending_page\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:identifier\").alias(\"identifier\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:publisher\").alias(\"publisher\"),\n",
    "\n",
    "    #array columns\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:creator.author\").alias(\"authors\"),\n",
    "    col(\"abstracts-retrieval-response.affiliation\").alias(\"affiliation\"),\n",
    "    col(\"abstracts-retrieval-response.subject-areas.subject-area\").alias(\"subject_area\"), #\n",
    "    col(\"abstracts-retrieval-response.authkeywords.author-keyword\").alias(\"authkeyword\"), #\n",
    "    col(\"abstracts-retrieval-response.idxterms.mainterm\").alias(\"idxterm\"), #\n",
    "    col(\"abstracts-retrieval-response.item.bibrecord.tail.bibliography.reference\").alias(\"reference_itemid\"), #\n",
    "    col(\"abstracts-retrieval-response.item.bibrecord.item-info.itemidlist.itemid\").alias(\"itemid\"), #\n",
    "\n",
    "    \n",
    "    # col(\"abstracts-retrieval-response.authors.author[0].preferred-name.ce:given-name\").alias(\"author_given_name\"),\n",
    "    # col(\"abstracts-retrieval-response.authors.author[0].preferred-name.ce:indexed-name\").alias(\"author_indexed_name\"),\n",
    "    # col(\"abstracts-retrieval-response.authors.author[0].ce:degrees\").alias(\"author_degrees\"),\n",
    "    # col(\"abstracts-retrieval-response.authors.author[0].@_fa\").alias(\"author_fa\"),\n",
    "    # col(\"abstracts-retrieval-response.authors.author[0].@auid\").alias(\"author_auid\"),\n",
    "    \n",
    "    # col(\"abstracts-retrieval-response.subject-areas.subject-area[0].@_fa\").alias(\"subject_area_fa\"),\n",
    "    # col(\"abstracts-retrieval-response.subject-areas.subject-area[0].$\").alias(\"subject_area_name\"),\n",
    "    # col(\"abstracts-retrieval-response.subject-areas.subject-area[0].@code\").alias(\"subject_area_code\"),\n",
    "    # col(\"abstracts-retrieval-response.subject-areas.subject-area[0].@abbrev\").alias(\"subject_area_abbrev\"),\n",
    "    \n",
    "    # col(\"abstracts-retrieval-response.authkeywords.author-keyword[0].@_fa\").alias(\"authkeyword_fa\"),\n",
    "    # col(\"abstracts-retrieval-response.authkeywords.author-keyword[0].$\").alias(\"authkeyword\"),\n",
    "    \n",
    "    # col(\"abstracts-retrieval-response.idxterms.mainterm[0].$\").alias(\"idxterm\"),\n",
    "    # col(\"abstracts-retrieval-response.idxterms.mainterm[0].@weight\").alias(\"idxterm_weight\"),\n",
    "    # col(\"abstracts-retrieval-response.idxterms.mainterm[0].@candidate\").alias(\"idxterm_candidate\"),\n",
    "    \n",
    "    # col(\"abstracts-retrieval-response.affiliation[0].affiliation-city\").alias(\"affiliation_city\"),\n",
    "    # col(\"abstracts-retrieval-response.affiliation[0].@id\").alias(\"affiliation_id\"),\n",
    "    # col(\"abstracts-retrieval-response.affiliation[0].affilname\").alias(\"affiliation_name\"),\n",
    "    # col(\"abstracts-retrieval-response.affiliation[0].affiliation-country\").alias(\"affiliation_country\"),\n",
    "    \n",
    "    # col(\"abstracts-retrieval-response.item.bibrecord.tail.bibliography.reference[0].ref-info.refd-itemidlist.itemid[1].$\").alias(\"reference_itemid\")\n",
    "]\n",
    "\n",
    "additional_data_selected_columns = [\n",
    "    #normal columns\n",
    "    col(\"abstracts-retrieval-response.coredata.srctype\").alias(\"source_type\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:doi\").alias(\"prism:doi\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:coverDate\").alias(\"cover_date\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:aggregationType\").alias(\"aggregation_type\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.source-id\").alias(\"source_id\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.citedby-count\").alias(\"citedby_count\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:volume\").alias(\"volume\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.subtype\").alias(\"subtype\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:title\").alias(\"title\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:issueIdentifier\").alias(\"issue_identifier\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.subtypeDescription\").alias(\"subtype_description\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:publicationName\").alias(\"publication_name\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:startingPage\").alias(\"starting_page\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:endingPage\").alias(\"ending_page\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:identifier\").alias(\"identifier\"),\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:publisher\").alias(\"publisher\"),\n",
    "\n",
    "    #array columns\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:creator.author\").alias(\"authors\"),\n",
    "    col(\"abstracts-retrieval-response.affiliation\").alias(\"affiliation\"),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "selected_df = df.select(*base_data_selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Distribution Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---------------+\n",
      "|        subject_area|date|aggregationType|\n",
      "+--------------------+----+---------------+\n",
      "|           Neurology|2022|        Journal|\n",
      "|Neurology (clinical)|2022|        Journal|\n",
      "|        Biochemistry|2020|        Journal|\n",
      "|  Molecular Medicine|2020|        Journal|\n",
      "|   Molecular Biology|2020|        Journal|\n",
      "|Pharmaceutical Sc...|2020|        Journal|\n",
      "|      Drug Discovery|2020|        Journal|\n",
      "|Clinical Biochemi...|2020|        Journal|\n",
      "|   Organic Chemistry|2020|        Journal|\n",
      "|Renewable Energy,...|2022|        Journal|\n",
      "|     Fuel Technology|2022|        Journal|\n",
      "|Condensed Matter ...|2022|        Journal|\n",
      "|Energy Engineerin...|2022|        Journal|\n",
      "|          Geophysics|2021|        Journal|\n",
      "|Earth and Planeta...|2021|        Journal|\n",
      "|   Multidisciplinary|2023|        Journal|\n",
      "|Public Health, En...|2023|        Journal|\n",
      "|Immunology and Al...|2022|        Journal|\n",
      "|          Immunology|2022|        Journal|\n",
      "|   Multidisciplinary|2023|        Journal|\n",
      "+--------------------+----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Topic Distribution Over Time\n",
    "\n",
    "Topic_Distribution_Columns = [\n",
    "    col(\"abstracts-retrieval-response.subject-areas.subject-area\").alias('subject_area'), #ดูจำนวน subject แต่ละอัน ในแต่ละปี\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:coverDate\").alias('date'), # ดูปี\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:aggregationType\").alias('aggregationType') #  เผื่อดูแยกแต่ละประเภทการตีพิมพ์\n",
    "]\n",
    "\n",
    "Topic_Distribution_df = df.select(*Topic_Distribution_Columns)\n",
    "\n",
    "#Topic_Distribution_df.select('subject_area').show(10, False)\n",
    "Topic_Distribution_df_exploded = Topic_Distribution_df.withColumn('subject_area',explode(col('subject_area').getItem('$')))\n",
    "\n",
    "Topic_Distribution_df_year = Topic_Distribution_df_exploded.withColumn('date',regexp_extract(col('date'),r'(\\d{4})',1))\n",
    "\n",
    "Topic_Distribution_df_year.show()\n",
    "\n",
    "# Topic_Distribution_df_exploded.groupBy('subject_area').count().orderBy('count', ascending=False).show(10, False)\n",
    "\n",
    "\n",
    "# Topic_Distribution_df_year.filter(col('subject_area').isNull()).show(10, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete! Check the output folder.\n"
     ]
    }
   ],
   "source": [
    "output_file = \"./output/Topic_Distribution_Data\"  # Replace with your desired output path\n",
    "# Save the extracted data to CSV\n",
    "try:\n",
    "    Topic_Distribution_df_year.coalesce(1).write.option(\"header\", True).mode('overwrite').csv(output_file)\n",
    "    print(\"Data extraction complete! Check the output folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
      "|title                                                                                                                                                                                            |SGR_id     |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives                                                             |85145388556|\n",
      "|Syntheses and anti-HIV and human cluster of differentiation 4 (CD4) down-modulating potencies of pyridine-fused cyclotriazadisulfonamide (CADA) compounds                                        |85096172220|\n",
      "|Effect of CoMo metal loading on H2 and CNTs production from biogas by integrative process                                                                                                        |85133691726|\n",
      "|Tropical Pacific Forcing of Hydroclimate in the Source Area of the Yellow River                                                                                                                  |85121026052|\n",
      "|Highly effective removal of perfluorooctanoic acid (PFOA) in water with DBD-plasma-enhanced rice husks                                                                                           |85168059883|\n",
      "|The prevalence and economic burden of treatment-resistant depression in Thailand                                                                                                                 |85167764240|\n",
      "|cGAS deficiency enhances inflammasome activation in macrophages and inflammatory pathology in pristane-induced lupus                                                                             |85145345425|\n",
      "|Development of eco-friendly antifungal and antibacterial adhesive derived from modified cassava starch waste/polyvinyl alcohol containing green synthesized nano-silver                          |85168236124|\n",
      "|Transcriptome analysis of Pueraria candollei var. mirifica for gene discovery in the biosyntheses of isoflavones and miroestrol                                                                  |85077258483|\n",
      "|Quantitative microbial risk assessment of the gastrointestinal risks to swimmers at Southeast Asian urban beaches using site-specific and combined autochthonous and fecal bacteria exposure data|85167455063|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#abstracts-retrieval-response.item.bibrecord.item-info.itemidlist.itemid //เอา SGR เป็นหลัก (ใช้ดู reference)\n",
    "#abstracts-retrieval-response.item.bibrecord.tail.bibliography.reference[0].ref-info.refd-itemidlist.itemid //เอา SGR เป็นหลัก (ใช้ดู reference)\n",
    "Citation_Network_Columns = [\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:title\").alias('title'),\n",
    "    col(\"abstracts-retrieval-response.item.bibrecord.item-info.itemidlist.itemid\").alias('SGR_id'), #ดูจำนวน subject แต่ละอัน ในแต่ละปี\n",
    "]\n",
    "Citation_Network_df = df.select(*Citation_Network_Columns)\n",
    "\n",
    "Citation_Network_df_exploded = Citation_Network_df.withColumn('SGR_id',explode(col('SGR_id')))\n",
    "\n",
    "filtered_df = Citation_Network_df_exploded.filter(col(\"SGR_id\").getItem('@idtype') == (\"SGR\"))\n",
    "\n",
    "Title_SGR_ID_df = filtered_df.withColumn('SGR_id', col('SGR_id').getItem('$'))\n",
    "\n",
    "Title_SGR_ID_df.show(10, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------+-----------+-----------+\n",
      "|title                                                                                                                               |SGR_id     |Ref        |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------+-----------+-----------+\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|85056435462|\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|33749638426|\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|85109038660|\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|84884471348|\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|84890120034|\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|85031787192|\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|84866173318|\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|84959364195|\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|84926517255|\n",
      "|Nuclear imaging for localization and surgical outcome prediction in epilepsy: A review of latest discoveries and future perspectives|85145388556|84884863091|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#abstracts-retrieval-response.item.bibrecord.tail.bibliography.reference[0].ref-info.refd-itemidlist.itemid //เอา SGR เป็นหลัก (ใช้ดู reference)\n",
    "Reference_Column = [\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:title\").alias('title'),\n",
    "    col(\"abstracts-retrieval-response.item.bibrecord.tail.bibliography.reference\").alias('Ref'),\n",
    "]\n",
    "\n",
    "Reference_df = df.select(*Reference_Column)\n",
    "Reference_df_exploded = Reference_df.withColumn('Ref',explode(col('Ref')))\n",
    "\n",
    "Reference_df_id = Reference_df_exploded.withColumn('Ref', col('Ref').getItem('ref-info').getItem('refd-itemidlist').getItem('itemid'))\n",
    "\n",
    "\n",
    "schema = ArrayType(StructType([\n",
    "    StructField(\"$\", StringType(), True),\n",
    "    StructField(\"@idtype\", StringType(), True)\n",
    "]))\n",
    "Reference_df_id_json = Reference_df_id.withColumn('Ref', from_json(col('Ref'), schema))\n",
    "\n",
    "Reference_df_id_exploded = Reference_df_id_json.withColumn('Ref',explode(col('Ref')))\n",
    "\n",
    "filtered_df_SGR = Reference_df_id_exploded.filter(col(\"Ref\").getItem('@idtype') == (\"SGR\"))\n",
    "\n",
    "Reference_df_SGR = filtered_df_SGR.withColumn('Ref', col('Ref').getItem('$'))\n",
    "\n",
    "Connection_df = Reference_df_SGR.join(Title_SGR_ID_df, Reference_df_SGR.title == Title_SGR_ID_df.title, 'left').drop(Title_SGR_ID_df.title).select('title','SGR_id','Ref')\n",
    "\n",
    "Connection_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete! Check the output folder.\n"
     ]
    }
   ],
   "source": [
    "output_file_1 = \"./output/Citation_network_title_id\"  \n",
    "output_file_2 = \"./output/Citation_network_ref\"  \n",
    "# Save the extracted data to CSV\n",
    "try:\n",
    "    Title_SGR_ID_df.coalesce(1).write.option(\"header\", True).mode('overwrite').csv(output_file_1)\n",
    "    Connection_df.coalesce(1).write.option(\"header\", True).mode('overwrite').csv(output_file_2)\n",
    "    print(\"Data extraction complete! Check the output folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Journal Impact Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abstracts-retrieval-response.coredata.prism:publicationName // แบ่งตามชื่อวารสาร\n",
    "#abstracts-retrieval-response.coredata.prism:aggregationType\n",
    "#abstracts-retrieval-response.coredata.citedby-count // เอามาคำนวณ impact factor\n",
    "#Impact factor คือ จำนวณ citation ทั้งหมดของวารสารนั้นๆ / จำนวน article ที่อยู่ในวารสารนั้น \n",
    "\n",
    "#Impact Factor (IF)= \n",
    "#Number of Articles in Journal / Sum of Citations for All Articles in Journal\n",
    "\n",
    "Journal_Impact_Column = [\n",
    "    col(\"abstracts-retrieval-response.coredata.dc:identifier\").alias('identifier'),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:publicationName\").alias('publication_name'),\n",
    "    col(\"abstracts-retrieval-response.coredata.prism:aggregationType\").alias('aggregationType'),\n",
    "    col(\"abstracts-retrieval-response.coredata.citedby-count\").alias('citedby_count'),\n",
    "    #เพิ่มเติม เป็นตัวแปรต้นสำหรับ predict\n",
    "    col(\"abstracts-retrieval-response.subject-areas.subject-area\").alias('subject_area'),\n",
    "    col(\"abstracts-retrieval-response.affiliation\").alias('affiliation'),\n",
    "    \n",
    "\n",
    "]\n",
    "Journal_Impact_df = df.select(*Journal_Impact_Column)\n",
    "\n",
    "# Journal_Impact_df.groupBy('publication_name').count().orderBy('count', ascending=False).show(10, False)\n",
    "Journal_Impact_df = Journal_Impact_df.withColumn(\n",
    "    'citedby_count', col('citedby_count').cast('int')\n",
    ")\n",
    "\n",
    "# เก็บไว้ก่อน\n",
    "# Journey_Count_By_Publication_Name = Journal_Impact_df.groupBy('publication_name').agg(\n",
    "#     sum('citedby_count').alias('total_citedby_count'),                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "#     count('citedby_count').alias('number_of_articles')\n",
    "#     ).orderBy('total_citedby_count', ascending=False)\n",
    "# Journey_Count_By_Publication_Name.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------------------------+-------------+----------------------+-----------------------+-----------------+\n",
      "|affiliation_vector                 |subject_area_vector                 |citedby_count|aggregationType_vector|publication_name_vector|identifier_vector|\n",
      "+-----------------------------------+------------------------------------+-------------+----------------------+-----------------------+-----------------+\n",
      "|(80,[0],[1.0])                     |(68,[23,30,37,47],[1.0,1.0,1.0,1.0])|0            |(3,[1],[1.0])         |(38,[5],[1.0])         |(47,[37],[1.0])  |\n",
      "|(80,[0,56],[1.0,1.0])              |(68,[5,9],[1.0,1.0])                |8            |(3,[0],[1.0])         |(38,[6],[1.0])         |(47,[17],[1.0])  |\n",
      "|(80,[0,21,59,71],[1.0,1.0,1.0,1.0])|(68,[9,16,19,21],[1.0,1.0,1.0,1.0]) |68           |(3,[0],[1.0])         |(38,[7],[1.0])         |(47,[1],[1.0])   |\n",
      "|(80,[0],[1.0])                     |(68,[3,21,39],[1.0,1.0,1.0])        |0            |(3,[0],[1.0])         |(38,[8],[1.0])         |(47,[36],[1.0])  |\n",
      "|(80,[0,3,57],[1.0,1.0,1.0])        |(68,[0],[1.0])                      |4            |(3,[0],[1.0])         |(38,[0],[1.0])         |(47,[0],[1.0])   |\n",
      "|(80,[0,3,57],[1.0,1.0,1.0])        |(68,[0],[1.0])                      |0            |(3,[0],[1.0])         |(38,[0],[1.0])         |(47,[13],[1.0])  |\n",
      "|(80,[0,3,57],[1.0,1.0,1.0])        |(68,[0],[1.0])                      |2            |(3,[0],[1.0])         |(38,[0],[1.0])         |(47,[10],[1.0])  |\n",
      "|(80,[0,3,57],[1.0,1.0,1.0])        |(68,[0],[1.0])                      |2            |(3,[0],[1.0])         |(38,[0],[1.0])         |(47,[11],[1.0])  |\n",
      "|(80,[0,3,57],[1.0,1.0,1.0])        |(68,[0],[1.0])                      |2            |(3,[0],[1.0])         |(38,[0],[1.0])         |(47,[12],[1.0])  |\n",
      "|(80,[0,40,72,74],[1.0,1.0,1.0,1.0])|(68,[61],[1.0])                     |13           |(3,[0],[1.0])         |(38,[9],[1.0])         |(47,[7],[1.0])   |\n",
      "+-----------------------------------+------------------------------------+-------------+----------------------+-----------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#start encoding subject_area\n",
    "Journal_Impact_df_exploded = Journal_Impact_df.withColumn('subject_area',explode(col('subject_area').getItem('$')))\n",
    "\n",
    "\n",
    "Journal_Impact_df_grouped = Journal_Impact_df_exploded.groupBy('publication_name').agg(\n",
    "    collect_list(\"subject_area\").alias(\"subject_area_list\"),\n",
    ")\n",
    "\n",
    "cv_subject = CountVectorizer(inputCol=\"subject_area_list\", outputCol=\"subject_area_vector\", binary=True)\n",
    "\n",
    "\n",
    "encode_subject_df = cv_subject.fit(Journal_Impact_df_grouped).transform(Journal_Impact_df_grouped).drop('subject_area_list').join(Journal_Impact_df, 'publication_name', 'left').drop('subject_area')\n",
    "\n",
    "#start encoding affiliation\n",
    "schema = ArrayType(StructType([\n",
    "    StructField(\"affiliation-city\", StringType(), True),\n",
    "    StructField(\"@id\", StringType(), True),\n",
    "    StructField(\"affilname\", StringType(), True),\n",
    "    StructField(\"affiliation-country\", StringType(), True),\n",
    "    StructField(\"@href\", StringType(), True),\n",
    "]))\n",
    "encode_subject_df_json = encode_subject_df.withColumn('affiliation', from_json(col('affiliation'), schema))\n",
    "\n",
    "encode_subject_df_json_exploded = encode_subject_df_json.withColumn('affiliation',explode(col('affiliation').getItem('affilname')))\n",
    "\n",
    "encode_subject_df_json_grouped = encode_subject_df_json_exploded.groupBy('publication_name').agg(\n",
    "    collect_list(\"affiliation\").alias(\"affiliation_list\"),\n",
    ")\n",
    "\n",
    "cv_affiliation = CountVectorizer(inputCol=\"affiliation_list\", outputCol=\"affiliation_vector\", binary=True)\n",
    "\n",
    "encode_affiliation_df = cv_affiliation.fit(encode_subject_df_json_grouped).transform(encode_subject_df_json_grouped).drop('affiliation_list').join(encode_subject_df_json, 'publication_name', 'left').drop('affiliation')\n",
    "\n",
    "\n",
    "#start encoding aggregationType & publication_name\n",
    "indexer_aggregation = StringIndexer(inputCol=\"aggregationType\", outputCol=\"aggregationType_index\")\n",
    "encoder_aggregation = OneHotEncoder(inputCol=\"aggregationType_index\", outputCol=\"aggregationType_vector\")\n",
    "\n",
    "indexer_publication = StringIndexer(inputCol=\"publication_name\", outputCol=\"publication_name_index\")\n",
    "encoder_publication = OneHotEncoder(inputCol=\"publication_name_index\", outputCol=\"publication_name_vector\")\n",
    "\n",
    "indexer_identifier = StringIndexer(inputCol=\"identifier\", outputCol=\"identifier_index\")\n",
    "encoder_identifier = OneHotEncoder(inputCol=\"identifier_index\", outputCol=\"identifier_vector\")\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer_aggregation, indexer_publication , indexer_identifier , encoder_aggregation, encoder_publication , encoder_identifier])\n",
    "\n",
    "encode_df = pipeline.fit(encode_affiliation_df).transform(encode_affiliation_df).drop('aggregationType' , 'aggregationType_index', 'publication_name' , 'publication_name_index', 'identifier', 'identifier_index')\n",
    "\n",
    "encode_df.show(10, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Science Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 8.216508340554153\n",
      "R2 Score: -0.3733746009680414\n"
     ]
    }
   ],
   "source": [
    "feature_columns = ['affiliation_vector', 'subject_area_vector', \n",
    "                   'aggregationType_vector', 'publication_name_vector', \n",
    "                   'identifier_vector']\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(encode_df)\n",
    "data = data.select(\"features\", \"citedby_count\")\n",
    "\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"citedby_count\", maxIter=100)\n",
    "model = gbt.fit(train_data)\n",
    "\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 8.216508340554153\n",
      "R2 Score: -0.3733746009680414\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"citedby_count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "r2_evaluator = RegressionEvaluator(labelCol=\"citedby_count\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = r2_evaluator.evaluate(predictions)\n",
    "print(f\"R2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10]) \\\n",
    "    .addGrid(gbt.maxIter, [50, 100]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "cv_model = crossval.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = cv_model.stages[-1]  # Last stage in the pipeline\n",
    "print(\"Feature Importances:\", rf_model.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [UNSUPPORTED_DATA_TYPE_FOR_DATASOURCE] The CSV datasource doesn't support the column `authors` of the type \"ARRAY<STRUCT<`@_fa`: STRING, `@auid`: STRING, `@seq`: STRING, affiliation: STRING, `author-url`: STRING, `ce:alias`: STRING, `ce:alt-name`: STRING, `ce:degrees`: STRING, `ce:given-name`: STRING, `ce:indexed-name`: STRING, `ce:initials`: STRING, `ce:suffix`: STRING, `ce:surname`: STRING, `preferred-name`: STRUCT<`ce:given-name`: STRING, `ce:indexed-name`: STRING, `ce:initials`: STRING, `ce:surname`: STRING>>>\".\n"
     ]
    }
   ],
   "source": [
    "output_file = \"./output/Data.csv\"  # Replace with your desired output path\n",
    "# Save the extracted data to CSV\n",
    "try:\n",
    "    selected_df.coalesce(1).write.option(\"header\", True).mode('overwrite').csv(output_file)\n",
    "    print(\"Data extraction complete! Check the output folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+----------+----------------+-----------+-------------+------+-------+--------------------+----------------+-------------------+--------------------+-------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|language|source_type|           prism:doi|cover_date|aggregation_type|  source_id|citedby_count|volume|subtype|               title|issue_identifier|subtype_description|    publication_name|starting_page|ending_page|          identifier|           publisher|             authors|         affiliation|        subject_area|         authkeyword|             idxterm|    reference_itemid|              itemid|\n",
      "+--------+-----------+--------------------+----------+----------------+-----------+-------------+------+-------+--------------------+----------------+-------------------+--------------------+-------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     eng|          j|10.3389/fneur.202...|2022-12-16|         Journal|21100212316|            0|    13|     re|Nuclear imaging f...|            NULL|             Review|Frontiers in Neur...|         NULL|       NULL|SCOPUS_ID:8514538...|Frontiers Media S.A.|[{true, 574627385...|[{\"affiliation-ci...|[{Neurology, true...|[{epilepsy, true}...|                NULL|[{NULL, 1, NULL, ...|[{2020884416, PUI...|\n",
      "|     eng|          j|10.1016/j.bmc.202...|2020-12-15|         Journal|      25786|            5|    28|     ar|Syntheses and ant...|              24|            Article|Bioorganic and Me...|         NULL|       NULL|SCOPUS_ID:8509617...|        Elsevier Ltd|[{true, 572054685...|[{\"affiliation-ci...|[{Biochemistry, t...|[{CD4, true}, {Ce...|[{Animals, n, b},...|[{NULL, 1, NULL, ...|[{2008507521, PUI...|\n",
      "|     eng|          j|10.1016/j.ijhyden...|2022-12-19|         Journal|      26991|            2|    47|     ar|Effect of CoMo me...|              98|            Article|International Jou...|        41444|      41460|SCOPUS_ID:8513369...|        Elsevier Ltd|[{true, 551739544...|[{\"affiliation-ci...|[{Renewable Energ...|[{Biogas, true}, ...|[{Active metals, ...|[{NULL, 1, NULL, ...|[{2019079425, PUI...|\n",
      "|     eng|          j|10.1029/2021GL095876|2021-12-16|         Journal|      27962|            6|    48|     le|Tropical Pacific ...|              23|             Letter|Geophysical Resea...|         NULL|       NULL|SCOPUS_ID:8512102...|John Wiley and So...|[{true, 572001420...|[{\"affiliation-ci...|[{Geophysics, tru...|                NULL|[{Basin discharge...|[{NULL, 1, NULL, ...|[{2014424328, PUI...|\n",
      "|     eng|          j|10.1038/s41598-02...|2023-12-01|         Journal|21100200805|            0|    13|     ar|Highly effective ...|               1|            Article|  Scientific Reports|         NULL|       NULL|SCOPUS_ID:8516805...|     Nature Research|[{true, 585377926...|[{\"affiliation-ci...|[{Multidisciplina...|                NULL|                NULL|[{NULL, 1, OB2Bib...|[{2024908503, PUI...|\n",
      "+--------+-----------+--------------------+----------+----------------+-----------+-------------+------+-------+--------------------+----------------+-------------------+--------------------+-------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- source_type: string (nullable = true)\n",
      " |-- prism:doi: string (nullable = true)\n",
      " |-- cover_date: string (nullable = true)\n",
      " |-- aggregation_type: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- citedby_count: string (nullable = true)\n",
      " |-- volume: string (nullable = true)\n",
      " |-- subtype: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- issue_identifier: string (nullable = true)\n",
      " |-- subtype_description: string (nullable = true)\n",
      " |-- publication_name: string (nullable = true)\n",
      " |-- starting_page: string (nullable = true)\n",
      " |-- ending_page: string (nullable = true)\n",
      " |-- identifier: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- @_fa: string (nullable = true)\n",
      " |    |    |-- @auid: string (nullable = true)\n",
      " |    |    |-- @seq: string (nullable = true)\n",
      " |    |    |-- affiliation: string (nullable = true)\n",
      " |    |    |-- author-url: string (nullable = true)\n",
      " |    |    |-- ce:degrees: string (nullable = true)\n",
      " |    |    |-- ce:given-name: string (nullable = true)\n",
      " |    |    |-- ce:indexed-name: string (nullable = true)\n",
      " |    |    |-- ce:initials: string (nullable = true)\n",
      " |    |    |-- ce:surname: string (nullable = true)\n",
      " |    |    |-- preferred-name: struct (nullable = true)\n",
      " |    |    |    |-- ce:given-name: string (nullable = true)\n",
      " |    |    |    |-- ce:indexed-name: string (nullable = true)\n",
      " |    |    |    |-- ce:initials: string (nullable = true)\n",
      " |    |    |    |-- ce:surname: string (nullable = true)\n",
      " |-- affiliation: string (nullable = true)\n",
      " |-- subject_area: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- $: string (nullable = true)\n",
      " |    |    |-- @_fa: string (nullable = true)\n",
      " |    |    |-- @abbrev: string (nullable = true)\n",
      " |    |    |-- @code: string (nullable = true)\n",
      " |-- authkeyword: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- $: string (nullable = true)\n",
      " |    |    |-- @_fa: string (nullable = true)\n",
      " |-- idxterm: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- $: string (nullable = true)\n",
      " |    |    |-- @candidate: string (nullable = true)\n",
      " |    |    |-- @weight: string (nullable = true)\n",
      " |-- reference_itemid: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- @aii:was-generated-by: string (nullable = true)\n",
      " |    |    |-- @id: string (nullable = true)\n",
      " |    |    |-- @reference-instance-id: string (nullable = true)\n",
      " |    |    |-- ce:source-text: string (nullable = true)\n",
      " |    |    |-- ref-fulltext: string (nullable = true)\n",
      " |    |    |-- ref-info: struct (nullable = true)\n",
      " |    |    |    |-- ref-authors: struct (nullable = true)\n",
      " |    |    |    |    |-- author: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- @_fa: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- @seq: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- ce:given-name: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- ce:indexed-name: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- ce:initials: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- ce:suffix: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- ce:surname: string (nullable = true)\n",
      " |    |    |    |    |-- collaboration: string (nullable = true)\n",
      " |    |    |    |    |-- et-al: string (nullable = true)\n",
      " |    |    |    |-- ref-publicationyear: struct (nullable = true)\n",
      " |    |    |    |    |-- @first: string (nullable = true)\n",
      " |    |    |    |-- ref-sourcetitle: string (nullable = true)\n",
      " |    |    |    |-- ref-text: string (nullable = true)\n",
      " |    |    |    |-- ref-title: struct (nullable = true)\n",
      " |    |    |    |    |-- ref-titletext: string (nullable = true)\n",
      " |    |    |    |-- ref-volisspag: struct (nullable = true)\n",
      " |    |    |    |    |-- pagerange: struct (nullable = true)\n",
      " |    |    |    |    |    |-- @first: string (nullable = true)\n",
      " |    |    |    |    |    |-- @last: string (nullable = true)\n",
      " |    |    |    |    |-- pages: string (nullable = true)\n",
      " |    |    |    |    |-- voliss: struct (nullable = true)\n",
      " |    |    |    |    |    |-- @issue: string (nullable = true)\n",
      " |    |    |    |    |    |-- @volume: string (nullable = true)\n",
      " |    |    |    |-- ref-website: struct (nullable = true)\n",
      " |    |    |    |    |-- ce:e-address: struct (nullable = true)\n",
      " |    |    |    |    |    |-- $: string (nullable = true)\n",
      " |    |    |    |    |    |-- @type: string (nullable = true)\n",
      " |    |    |    |-- refd-itemidlist: struct (nullable = true)\n",
      " |    |    |    |    |-- itemid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "examver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
